---
layout: default
title: Projects & Portfolio
---

<br/>
## Research Areas

<div class="about-section">

<h3>Human-Guided Reinforcement Learning</h3>
<p>Developing algorithms that enable humans to effectively train and shape autonomous agents through demonstrations, real-time interventions, evaluative feedback, and natural language guidance. This includes foundational work on interactive agent shaping (Deep TAMER), the Cycle-of-Learning framework, and rating-based reinforcement learning.</p>

<h3>Deep Reinforcement Learning & Multi-Agent Systems</h3>
<p>Exploring deep reinforcement learning techniques for complex environments including video games (Atari, StarCraft II, Minecraft) and multi-agent coordination for human-robot collaboration and autonomous systems in tactical environments.</p>

<h3>Large Language Models & Generative AI</h3>
<p>Applying human-guided machine learning principles to LLMs for command and control planning, leveraging human feedback to steer and align generative AI systems.</p>

</div>

## Featured Projects

<div class="projects-grid">

  <div class="project-card">
    <h3>Deep TAMER</h3>
    <p>Extended interactive agent shaping to high-dimensional state spaces using deep learning. Enables non-expert humans to train agents in complex environments like Atari games by providing evaluative feedback (positive/negative signals) rather than explicit demonstrations. Published at <strong>AAAI 2018</strong>.</p>
    <div class="project-tags">
      <span class="project-tag">Human-in-the-Loop RL</span>
      <span class="project-tag">Deep Learning</span>
      <span class="project-tag">AAAI</span>
    </div>
    <div class="project-links">
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/11485">Publication</a>
    </div>
  </div>

  <div class="project-card">
    <h3>Cycle-of-Learning</h3>
    <p>A unified framework integrating multiple human interaction modalities—demonstrations, real-time interventions, and evaluative feedback—into reinforcement learning. Defines switching criteria between modalities for efficient autonomous system training. Published at <strong>AAAI 2019</strong>.</p>
    <div class="project-tags">
      <span class="project-tag">Human-Guided RL</span>
      <span class="project-tag">Imitation Learning</span>
      <span class="project-tag">AAAI</span>
    </div>
    <div class="project-links">
      <a href="https://arxiv.org/abs/1808.09572">arXiv</a>
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/4091">AAAI</a>
    </div>
  </div>

  <div class="project-card">
    <h3>Narration-Guided RL for StarCraft II</h3>
    <p>A novel approach using natural language narration to address reward sparsity in deep RL. Projects language commands into a shared representation with goal states, enabling agents to learn tasks that were previously unlearnable in complex environments like StarCraft II.</p>
    <div class="project-tags">
      <span class="project-tag">Language-Guided RL</span>
      <span class="project-tag">StarCraft II</span>
      <span class="project-tag">NLP</span>
    </div>
    <div class="project-links">
      <a href="https://arxiv.org/abs/1911.00497">arXiv</a>
    </div>
  </div>

  <div class="project-card">
    <h3>Rating-based Reinforcement Learning</h3>
    <p>A framework allowing humans to train agents using intuitive numerical ratings rather than binary feedback or demonstrations. Extends the types of human feedback that can be leveraged for RL. Published at <strong>AAAI 2024</strong>.</p>
    <div class="project-tags">
      <span class="project-tag">Human Feedback</span>
      <span class="project-tag">Reinforcement Learning</span>
      <span class="project-tag">AAAI</span>
    </div>
    <div class="project-links">
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28886">Publication</a>
    </div>
  </div>

  <div class="project-card">
    <h3>GUIDE: Real-Time Human-Shaped Agents</h3>
    <p>Enables continuous human feedback grounded into dense rewards. Features a simulated feedback module that learns to replicate human guidance patterns. With only 10 minutes of human feedback, achieves up to 30% increase in success rate. Published at <strong>NeurIPS 2024</strong>.</p>
    <div class="project-tags">
      <span class="project-tag">Real-Time RL</span>
      <span class="project-tag">Human Feedback</span>
      <span class="project-tag">NeurIPS</span>
    </div>
    <div class="project-links">
      <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/facf3192e99ce60c0ef5ed4067b72f68-Abstract-Conference.html">Publication</a>
    </div>
  </div>

  <div class="project-card">
    <h3>Multi-Agent Curriculum Learning in StarCraft II</h3>
    <p>Learning to guide multiple heterogeneous actors from a single human demonstration via automatic curriculum learning. Addresses the challenge of multi-agent coordination from limited human input.</p>
    <div class="project-tags">
      <span class="project-tag">Multi-Agent RL</span>
      <span class="project-tag">Curriculum Learning</span>
      <span class="project-tag">StarCraft II</span>
    </div>
    <div class="project-links">
      <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12113/0000/Learning-to-guide-multiple-heterogeneous-actors-from-a-single-human/10.1117/12.2622154.short">Publication</a>
    </div>
  </div>

  <div class="project-card">
    <h3>DIP-RL: Demonstration-Inferred Preference Learning</h3>
    <p>Novel approach to learning from human demonstrations in Minecraft environments. Bridges the gap between human intuition and AI learning through preference inference.</p>
    <div class="project-tags">
      <span class="project-tag">Preference Learning</span>
      <span class="project-tag">Human Feedback</span>
      <span class="project-tag">Minecraft</span>
    </div>
    <div class="project-links">
      <a href="https://arxiv.org/abs/2307.12158">arXiv</a>
    </div>
  </div>

  <div class="project-card">
    <h3>COA-GPT</h3>
    <p>Applying human-guided ML principles to LLMs for accelerated Course of Action development in military operations. Demonstrates how RL concepts extend to generative AI for Command and Control planning.</p>
    <div class="project-tags">
      <span class="project-tag">LLMs</span>
      <span class="project-tag">Generative AI</span>
      <span class="project-tag">C2 Planning</span>
    </div>
    <div class="project-links">
      <a href="https://ieeexplore.ieee.org/abstract/document/10540749/">Publication</a>
    </div>
  </div>

</div>


## Collaborations & Competitions

- **MineRL BASALT 2022 Competition** - Contributed to solving fuzzy tasks with human feedback in Minecraft environments
- **NeurIPS 2021 Competition** - Retrospective on learning from human feedback
- **AAAI, ICML, NeurIPS, AAMAS** - Regular presenter and contributor to top-tier AI/ML conferences

---

<p style="text-align: center; margin-top: 3rem;">
  <a href="index.html" style="color: var(--primary-color); font-weight: 500;">← Back to Home</a>
</p>
